# The Bull Protocol

This protocol description is based on [**bull**](https://github.com/OptimalBits/bull) version 1.0.0-rc2. The goal is to extract a common protocol to produce/consume jobs like **bull** that can be implemented across different languages.

Acknowledgement is given to [manast](https://github.com/manast) for creating the great **bull** library.

### Progress Tracker

- [x] Data Structure Definitions
- [ ] Inner Queue Protocol
- [ ] Job Promotion Protocol
- [ ] Job Execution Protocol
- [ ] Exception Handling (ACK, TTL)

### Overview

As per its original implementation, bull is designed to be a "lightweight, robust and fast job processing queue". Under the hood bull relies on `redis`, where the data resides. 

According to the source code, the data structures within `redis` are as follows:

```
- wait (list)
- active (list)
- delayed (zset)
- completed (set)
- failed (set)
                       -- >completed
                      /
job -> wait -> active
    |    ^            \
    v    |             -- > failed
    delayed
    
failed -> wait -> active (optional)
```

The detailed job data is stored in its own hash set. Usually only the job id and  the relevant parameter (the delay amount for example) are used in the data structures. In addition, a key based locking mechanism is implemented using redis as well.

`wait`: a list of ids for jobs that are due for processing, implemented as a list in redis.

`active`: a list of ids for jobs that are currently being processed. The moving of job id from `wait` to `active` should be atomic.

`completed`: a set of ids for jobs that have been completed. The set is not ordered.

`failed`: a set of ids for jobs that have failed. The set is not ordered.

`delayed`: a sorted set of ids for jobs that are scheduled to be processed sometime in the future. The set is sorted by a value that is caculated with the delay amount and the job id of the job, in order to achieve best effort FIFO.

### Key Structure

All keys are prefixed by `[general prefix]:[queue name]:`, where `general prefix` is default `bull`, but can be set to anything per the option, and `queue name` being the name of the queue.

We will refer to the prefix by `PREFIX` in the rest of the protocol description.

### Job Data

Job data is recorded in a hash set, with the following parameters:

```
data: JSON formatted data of the job, set by the application
opts: JSON formatted job options
progress: the percentage progress of the job, between 0 and 1
delay: the delay amount (in ms) of the job
timestamp: a UNIX timstamp representing when the job is created
attempts: maximum number of process attempts before giving up
attemptsMade: number of process attempts made so far
stacktrace: JSON formatted array of stack traces for errors occurred
returnvalue: JSON formatted data of the return value of the job
```

The key format 

`PREFIX:JOBID`

The job id is generated by incrementing the `PREFIX:id` key in redis.

### Adding Job to Queue

There are several steps:

#### 1. Create the entry of the job data

This should be done via a lua script following these steps:

- Increment the job id counter (`PREFIX:id`), and use the return value as the job id
- Use `HMSET` to store the job parameters (as described in the Job Data section) to the job key (`PREFIX:JOBID`)

#### 2. Add job to the `wait` list if no delay time

The client must check the delay timestamp and see if the job ETA is now or in the past: if so, the job is to be added directly to the `wait` list, either using a `LPUSH` or `RPUSH` (`RPUSH` is used for the last in first out scenario).

#### 3. Add job to the `delayed` zset if delay time exists

If the job is to be executed sometime in the future, the job is to be added to `delayed` instead of `wait`.

The score of the job in the `delayed` is calculated by the following method:

`ETA_TIMESTAMP * 0x1000 + JOBID % 0x1000`

where `ETA_TIMESTAMP` is the timestamp at which the job should be executed (calculated by now + delay), and the `JOBID` is the id of the job, from step 1.

This may seem weird, but it's needed for achieving best effort first in first out. Consider the situation where the score of the job is the ETA timestamp: two jobs are added, first job is added with an ETA of time `t`, the second job is also added with an ETA of time `t`, but added much later; when the jobs are promoted from the `delayed` set to the `wait` set for execution, the job added later, having the same timestamp as the first job, is promoted first. To achieve FIFO, the first job should be executed first, therefore we should take the job id into consideration when calculating the score, since a small job id indicates the job is added earlier.

In redis, the score of a zset is a [double precision float point number](https://en.wikipedia.org/wiki/Double-precision_floating-point_format), the max value of which can represent is about **900719925474099**. To achieve some degree of FIFO, the score must be smaller for a job added earlier than a job added later with the same ETA timestamp. The way to do so is to increase the magnitude of ETA timestamp, then bake some form of the job id into its value.

In this case, we are multiplying the timestamp by 0x1000 (4096 in decimal), and then add the result of job id mod 0x1000 (which equals the bitwise and product of job id and 0x1000 - 1). As a result, the maximum ETA timestamp supported is 900719925474099 / 4096, which roughly translates to **September, 2039**. 

Well, hopefully you have found a better library by the year 2039.

#### 4. Publish the delayed timestamp to the `delayed` channel if delay time exists

`PUBLISH PREFIX:delayed ETA_TIMESTAMP`

Note that it is the ETA_TIMESTAMP, not the score of job in the `delayed` set.